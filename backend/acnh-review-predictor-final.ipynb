{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was used to create the model used in the final application where a user can input a review of Animal Crossing: New Horizons and receive a predicted sentiment based on their review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, regexp_tokenize, FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model to be able to process raw text, I create a function that inherits the tokenizing process, the removal of stopwords, and the lemmatizing of the text from the original notebook so the review text goes through all these cleaning and preprocessing steps before being taken in by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(user_input):\n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    review_text = regexp_tokenize(user_input, pattern)\n",
    "    review_text = ' '.join(review_text)\n",
    "    review_text = review_text.lower()\n",
    "\n",
    "    \n",
    "    stopwords_list = stopwords.words('english')\n",
    "    stopwords_list += list(string.punctuation)\n",
    "    stopwords_list += ['game', 'animal', 'crossing']\n",
    "    review_text = [w for w in review_text.split() if w not in stopwords_list]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    review_text = [lemmatizer.lemmatize(w) for w in review_text]\n",
    "    review_text = ' '.join(review_text)\n",
    "        \n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recreate the model to pickle and load into our application, I import the same dataset we originally used and label the data again the same way as I originally did in my initial notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/user_reviews.csv')\n",
    "def sentiment_labels(row):\n",
    "    if row['grade'] >= 8:\n",
    "        val = 'positive'\n",
    "    elif row['grade'] <= 4:\n",
    "        val = 'negative'\n",
    "    else:\n",
    "        val = 'neutral'\n",
    "    return val\n",
    "df['sentiment'] = df.apply(sentiment_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already have our best model and optimal parameters, we won't need to perform a train-test split on our dataset again, and can instead assign X and y to the `text` and `sentiment` columns respectively for our feature and target. I then apply the `text_processing` function to prepare the `text` column for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       gf started playing option create island guy nd...\n",
       "1       great really relaxing gorgeous can't ignore on...\n",
       "2       wife looking forward playing released bought l...\n",
       "3       need equal value opportunity player island wif...\n",
       "4       beware multiple people house want play account...\n",
       "                              ...                        \n",
       "2994    island console limitation cannot play girlfrie...\n",
       "2995    per giocare con figli fidanzate mogli persone ...\n",
       "2996    one island per console pathetic limitation end...\n",
       "2997    even though seems like great many item charact...\n",
       "2998    fantastic nintendo deciding make one island pe...\n",
       "Name: text, Length: 2999, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_X  = X.apply(text_processing)\n",
    "model_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking note of the optimal parameters provided to us from performing a grid search on our logistic regression model, we then create a pipeline and fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('smote', SMOTE(sampling_strategy='not majority')),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.2, penalty='none'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.2, penalty='none')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "smote = SMOTE(sampling_strategy='not majority')\n",
    "    \n",
    "pipeline = make_pipeline(tfidf_vectorizer, smote, model)\n",
    "\n",
    "model_X  = X.apply(text_processing)\n",
    "    \n",
    "pipeline.fit(model_X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pickle, we extract (or \"pickle\") the model from the pipeline we fitted onto our pre-existing data into a `.pkl` file so that we can use the same model to predict sentiment later in our application. To test the extracted model and make sure it works as intended, I reload the same `.pkl` model into this notebook and use it to predict the sentiment of a test input string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('acnh_review_model.pkl', 'wb')\n",
    "pickle.dump(pipeline, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('acnh_review_model.pkl', 'rb')\n",
    "loaded_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'negative', ..., 'negative', 'positive',\n",
       "       'negative'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I love this game so much!\n",
      "Prediction: ['positive']\n"
     ]
    }
   ],
   "source": [
    "# Test input #1: positive review\n",
    "user_input = \"I love this game so much!\"\n",
    "print('Input:', user_input)\n",
    "\n",
    "cleaned_text = text_processing(user_input)\n",
    "print('Prediction:', loaded_model.predict([cleaned_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: This game was terrible lol New Leaf was better\n",
      "Prediction: ['negative']\n"
     ]
    }
   ],
   "source": [
    "# Test input #2: negative review\n",
    "user_input = \"This game was terrible lol New Leaf was better\"\n",
    "print('Input:', user_input)\n",
    "\n",
    "cleaned_text = text_processing(user_input)\n",
    "print('Prediction:', loaded_model.predict([cleaned_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like both test inputs were predicted accurately, so we're ready to implement our predictive model into an external application with our pickled model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
